{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e74e4d7",
   "metadata": {},
   "source": [
    "# Mount your own Google Drive\n",
    "\n",
    "Allow Google Drive for desktop full access to your Google Account. (You can remove it later again in your Google account settings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e31c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1aed5",
   "metadata": {},
   "source": [
    "# Clone the repository to your Google Drive\n",
    "\n",
    "Next, we change the directory to your Google Drive content drive, clone the public repository that our group prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd gdrive/MyDrive/\n",
    "! git clone https://github.com/UzL-PrivSec/summer-school-2024.git\n",
    "%cd summer-school-2024/\n",
    "%cd adversarial_examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b09273",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dae18e-aed3-4b27-b83b-6b22d92cc995",
   "metadata": {
    "id": "e2dae18e-aed3-4b27-b83b-6b22d92cc995"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.MnistNet import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdf907",
   "metadata": {},
   "source": [
    "## Download the pre-trained model weights and the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190498f-1287-4b9a-914a-772c0db7afed",
   "metadata": {
    "id": "3190498f-1287-4b9a-914a-772c0db7afed"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(\"./data/mnist_cnn.pt\"))  # Load pre-trained weights\n",
    "model.eval()  # Avoid any backpropagation\n",
    "\n",
    "dataset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "data_loader = torch.utils.data.DataLoader(dataset, **{\"batch_size\": 1, \"shuffle\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3452a28",
   "metadata": {},
   "source": [
    "## Programming Exercise: Adversarial Examples\n",
    "\n",
    "Paper link: https://arxiv.org/abs/1412.6572 \n",
    "\n",
    "The code itself implements the FGSM (Fast Gradient Sign Method). Please fill out the missing code pieces marked with \"TODO a)\" to create an untargeted FGSM \n",
    "and \"TODO b)\"'s to create a targeted FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0098e7-78aa-4c4c-b7d8-bfc3518141ea",
   "metadata": {
    "id": "1f0098e7-78aa-4c4c-b7d8-bfc3518141ea"
   },
   "outputs": [],
   "source": [
    "eps = 1  # Upper bound for the noise\n",
    "eps_step = 1/20  # Increase of the noise\n",
    "\n",
    "# In case of a targeted attack we need to specify the targeted class\n",
    "target_label = None\n",
    "#target_label = torch.Tensor([0]).type(torch.LongTensor).to(device)\n",
    "targeted = target_label != None  # True if <target_label> != None else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d4915",
   "metadata": {},
   "source": [
    "The next two cells contain the holes in the code that you have to fill. As explained above, the holes are marked as \"TODO a)\" and \"TODO b)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a75a0-45e8-460f-8242-3717ff3b679a",
   "metadata": {
    "id": "507a75a0-45e8-460f-8242-3717ff3b679a"
   },
   "outputs": [],
   "source": [
    "def get_grad_signs(x, y):\n",
    "    \"\"\"\n",
    "    Feed the given input into the model and get the gradient wrt the desired label.\n",
    "    The FGSM only requires the signs of the gradient.\n",
    "\n",
    "    :param data: A single image\n",
    "    :param label: The desired output label\n",
    "\n",
    "    :return: The sign of the created gradient wrt the desired label\n",
    "    \"\"\"\n",
    "\n",
    "    # Forward propagate input\n",
    "    output = model(x)\n",
    "\n",
    "    # Create desired gradients\n",
    "    # Note: Use <F.nll_loss> as loss funtion\n",
    "    loss = # TODO a) #\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Get signs of gradient [[0.5, 0, -0.7, 3], ...] -> [[1, 0, -1, 1], ...]\n",
    "    # Note: Use <x.grad.data> to access the gradient\n",
    "    sign = # TODO a) #\n",
    "\n",
    "    # Invert every sign in case of a targeted attack\n",
    "    if targeted:\n",
    "        # TODO b) #\n",
    "        pass\n",
    "\n",
    "    return sign\n",
    "\n",
    "\n",
    "def apply_perturbation(x, gradient_signs, eps):\n",
    "    \"\"\"\n",
    "    Apply a perturbation onto the given image.\n",
    "    The strength of the applied perturbation is controlled by <eps>.\n",
    "\n",
    "    :param x: A single image\n",
    "    :param gradient_signs: The signs of the gradient with the same shape as the input image\n",
    "    :param eps: A skalar which controlles the strength of the applied perturbation\n",
    "\n",
    "    :return: A modified version of the given image\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate perturbation -> eps * sign(gradient)\n",
    "    perturbation = # TODO a) #\n",
    "\n",
    "    # Add perturbation to the image\n",
    "    x = x + perturbation\n",
    "\n",
    "    # Ensure that every pixel value is still in the interval [0,1]\n",
    "    x = # TODO a) #\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02138b8c-e018-4bdc-bb89-7669538e4eed",
   "metadata": {
    "id": "02138b8c-e018-4bdc-bb89-7669538e4eed"
   },
   "outputs": [],
   "source": [
    "def minimal_perturbation(x, y):\n",
    "    \"\"\"\n",
    "    Try to find a perturbation based on a minimal epsilon such that...\n",
    "    a) Untargeted attack: the model classifies the given image into an arbitrary class\n",
    "    b) Targeted attack: the model classifies the given image into the class <target_label>\n",
    "\n",
    "    :param x: A single image\n",
    "    :param y: The original class label of the given image\n",
    "\n",
    "    :return: (adversarial example, new label) as tuple or None if no adversarial example could be generated\n",
    "    \"\"\"\n",
    "\n",
    "    # In case of a targeted attack set the desired label\n",
    "    if targeted:\n",
    "        y = target_label\n",
    "\n",
    "    # Get signs of the desired gradient\n",
    "    gradient_signs = get_grad_signs(x, y)\n",
    "\n",
    "    current_eps = eps_step\n",
    "    partial_stop_condition = current_eps <= eps\n",
    "\n",
    "    while partial_stop_condition:\n",
    "\n",
    "        current_adv_x = apply_perturbation(x, gradient_signs, current_eps)\n",
    "\n",
    "        # Predict new label\n",
    "        adv_preds = # TODO a) #\n",
    "        new_label = adv_preds.argmax(dim=1, keepdim=True)[0].cpu().detach()\n",
    "\n",
    "        # Untargeted attack: Check if we get another arbitrary label\n",
    "        if not targeted:\n",
    "            flipped = # TODO a) #\n",
    "        # Targeted attack: Check if we get the desired label\n",
    "        else:\n",
    "            flipped = # TODO b) #\n",
    "\n",
    "        # Update current eps and check the stop condition\n",
    "        current_eps += eps_step\n",
    "        partial_stop_condition = current_eps <= eps\n",
    "\n",
    "        # If we successfully generated an adversarial example then save it in combination with its new label\n",
    "        if flipped:\n",
    "            return current_adv_x.detach().cpu(), new_label\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc032aab",
   "metadata": {},
   "source": [
    "This is a helper function that iterates the given dataset and tries to find an adversarial example for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681824d8-14ce-429a-b28a-66ba62bdf7d7",
   "metadata": {
    "id": "681824d8-14ce-429a-b28a-66ba62bdf7d7"
   },
   "outputs": [],
   "source": [
    "def generate(data_loader, device):\n",
    "    \"\"\"\n",
    "    Iterates the given dataset and tries to find an adversarial example for every image.\n",
    "\n",
    "    :param data_loader: Dataset packed in an iterable data loader\n",
    "    :param device: PyTorch device\n",
    "\n",
    "    :return: A list of adversarial examples with the following structure\n",
    "             [(original_img, original_label, adversarial_img, adversarial_label), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    x_advs = list()\n",
    "\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        data.requires_grad = True  # To generate gradients...\n",
    "\n",
    "        # This does not make much sense...\n",
    "        if targeted:\n",
    "            if label == target_label:\n",
    "                continue\n",
    "\n",
    "        # Search for an adversarial example\n",
    "        x_adv = minimal_perturbation(data, label)\n",
    "        if x_adv != None:\n",
    "            x_advs.append( (data.detach().cpu(), label.detach().cpu(), *x_adv) )\n",
    "\n",
    "        # You don't have to iterate all 10,000 images...\n",
    "        if i >= 10:\n",
    "            break\n",
    "\n",
    "    return x_advs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330f872",
   "metadata": {},
   "source": [
    "For convenience, next comes the code to display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbded1c8-14ed-46d1-9b15-7223d8895cf9",
   "metadata": {
    "id": "dbded1c8-14ed-46d1-9b15-7223d8895cf9"
   },
   "outputs": [],
   "source": [
    "adv_examples = generate(data_loader, device)\n",
    "\n",
    "print(f\"Found {len(adv_examples)} adversarial examples...\")\n",
    "\n",
    "# Use this to plot some images and their corresponding adversarial versions\n",
    "for org, org_label, adv, adv_label in adv_examples:\n",
    "\n",
    "    plt.imshow(org[0][0])\n",
    "    plt.title(f\"Label: {org_label}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(adv[0][0])\n",
    "    plt.title(f\"Label: {adv_label}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
