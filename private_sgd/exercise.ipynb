{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Important: If you are using Google Colab, please make sure to select a GPU as an accelerator. This is done via **Runtime -> Change Runtime Type -> Hardware Accelerator.**"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Wnw_a8MGU_7F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from typing import Iterable\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PyHOtIBAU_7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# define a simple model with 2 fully-connected layers\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.log_softmax(self.fc2(x), dim = 1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ol2g3_qKU_7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# calculate the l2-norm of the model's gradient.\n",
        "# as the model consists of several layers, we have to aggregate the gradients of all layers and calculate\n",
        "# the overall norm.\n",
        "def calc_grad_norm(parameters: Iterable[torch.Tensor], device):\n",
        "    return torch.norm(torch.stack([torch.norm(p.grad.detach()).to(device) for p in parameters]))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xvPDoqvYU_7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# clip the model's gradient to max_grad_norm\n",
        "def clip_(parameters: Iterable[torch.Tensor], max_grad_norm: float, device):\n",
        "    parameters = [p for p in parameters if p.grad is not None]\n",
        "\n",
        "    ## TODO ##\n",
        "    # implement the actual clipping.\n",
        "    # tips: - remember that you can access each layer's gradient by using \"p.grad for each p in parameters\"\n",
        "    #       - you can manipulate the gradients in this function in-place without returning anything\n",
        "    #       - clipping can be implemented as a multiplication of each gradient with a scaling factor\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3B8AgsshU_7L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, noise_multiplier, max_grad_norm):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # we use reduction='none' so that we get the loss per sample in our batch\n",
        "    criterion =  nn.NLLLoss(reduction='none')\n",
        "\n",
        "    losses = []\n",
        "    top1_acc = []\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        min_max_grad_norm = 1e15\n",
        "\n",
        "        # prepare a dict to store single gradients by its layer's name\n",
        "        clipped_grads = {name: torch.zeros_like(param, device=device) for name, param in model.named_parameters()}\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )\n",
        "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "        top1_acc.append(correct / len(data))\n",
        "\n",
        "        for i in range(loss.size(0)):\n",
        "            loss[i].backward(retain_graph=True)\n",
        "\n",
        "            clip_(model.parameters(), max_grad_norm, device)\n",
        "\n",
        "            for name, param in model.named_parameters():\n",
        "                clipped_grads[name] += param.grad.detach().clone() / loss.size(0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        ## TODO: add noise ##\n",
        "        for key in clipped_grads.keys():\n",
        "            # 1. create appropriately scaled noise\n",
        "            # tip: the function torch.normal(...) may help you\n",
        "\n",
        "\n",
        "            # 2. add the noise to our accumulated gradients\n",
        "            # clipped_grads[key] ...\n",
        "\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            param.grad = clipped_grads[name]\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(torch.mean(loss).item())\n",
        "\n",
        "    mean_loss = np.mean(losses)\n",
        "    mean_acc = np.mean(top1_acc)\n",
        "\n",
        "    print(f'Train Epoch {epoch}: \\t Loss: {mean_loss:.6f}; Acc@1: {mean_acc:.6f}')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sy8vsNtPU_7L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for data, targets in tqdm(test_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, targets).item()\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )\n",
        "            correct += pred.eq(targets.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            len(test_loader.dataset),\n",
        "            100.0 * correct / len(test_loader.dataset),\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bLJSql9JU_7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    lr = 5e-3\n",
        "    train_batch_size = 32\n",
        "    test_batch_size = 1000\n",
        "    epochs = 10\n",
        "    sigma = 1.1 # noise multiplier\n",
        "    c = 1.0 # clipping bound\n",
        "\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda:0\" if cuda_available else \"cpu\")\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            \"../mnist\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                ]\n",
        "            ),\n",
        "        ),\n",
        "        batch_size=train_batch_size,\n",
        "        num_workers=1,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            \"../mnist\",\n",
        "            train=False,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                ]\n",
        "            ),\n",
        "        ),\n",
        "        batch_size=test_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=1,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    model = Model().to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1), desc=\"Epoch\", unit=\"epoch\"):\n",
        "\n",
        "        train(model, device, train_loader, optimizer, epoch, sigma, c)\n",
        "\n",
        "        test(model, device, test_loader)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "PzBFFtQMU_7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yESuV6KHU_7N"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}