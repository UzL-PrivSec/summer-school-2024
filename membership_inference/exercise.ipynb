{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d141dd29",
      "metadata": {
        "id": "d141dd29"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c82cc3f3",
      "metadata": {
        "id": "c82cc3f3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from IPython.display import clear_output\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aaaaf949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaaaf949",
        "outputId": "d2d3a1b7-6d66-4855-d029-33f654ab6e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 31034543.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = datasets.CIFAR10(\"./data/\", train=True, download=True, transform=transform)\n",
        "\n",
        "train_target_dataset = torch.utils.data.Subset(dataset, torch.arange(0, 7500))\n",
        "train_target_loader  = torch.utils.data.DataLoader(train_target_dataset, batch_size=128, shuffle=True, num_workers=1)\n",
        "\n",
        "test_target_dataset = torch.utils.data.Subset(dataset, torch.arange(7500,15000))\n",
        "test_target_loader  = torch.utils.data.DataLoader(test_target_dataset, batch_size=256, shuffle=True, num_workers=1)\n",
        "\n",
        "train_shadow_dataset = torch.utils.data.Subset(dataset, torch.arange(22500,30000))\n",
        "train_shadow_loader  = torch.utils.data.DataLoader(train_shadow_dataset, batch_size=128, shuffle=True, num_workers=1)\n",
        "\n",
        "test_shadow_dataset = torch.utils.data.Subset(dataset, torch.arange(30000,37500))\n",
        "test_shadow_loader  = torch.utils.data.DataLoader(test_shadow_dataset, batch_size=128, shuffle=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "765cb264",
      "metadata": {
        "id": "765cb264"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We have to make the architecture available to be able to load models from file.\n",
        "\"\"\"\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3,  32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=4)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=4)\n",
        "\n",
        "        self.act = nn.Tanh()\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "edbfc466",
      "metadata": {
        "id": "edbfc466"
      },
      "outputs": [],
      "source": [
        "def get_losses(model: nn.Module, data_loader: torch.utils.data.DataLoader) -> torch.tensor:\n",
        "    \"\"\"\n",
        "    Get loss for every sample in <data_loader> of the <model>.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    losses = torch.zeros(len(data_loader.dataset))\n",
        "\n",
        "    bz = data_loader.batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = F.cross_entropy(output, target, reduction=\"none\").cpu()\n",
        "\n",
        "            losses[i * bz : (i+1) * bz] = loss\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5fc90e8",
      "metadata": {
        "id": "c5fc90e8"
      },
      "source": [
        "## Part I: Baseline Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "31f8234a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "31f8234a",
        "outputId": "6d99ef18-4fda-4259-9e6e-8dcc4ed8f3d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-9367ca29ef1a>, line 11)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-9367ca29ef1a>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    losses =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def compare_with_loss(data_loader: torch.utils.data.DataLoader, target_loss: float, *, is_member: bool) -> int:\n",
        "    \"\"\"\n",
        "    Determine the number of members or non-members by comparing each loss value with the target loss.\n",
        "    We call samples a member if the corresponding loss value is less than the target loss. The opposite holds for non-members.\n",
        "    This method returns the estimated number of members or non-members.\n",
        "    \"\"\"\n",
        "\n",
        "    num = 0\n",
        "\n",
        "    # TODO: Get loss values for all samples #\n",
        "    losses =\n",
        "\n",
        "    # TODO: Compare each loss value with the target loss and increase the number of members / non-members if necessary #\n",
        "\n",
        "    return num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3114cbc",
      "metadata": {
        "id": "e3114cbc"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"./data/target_model.mdl\")\n",
        "\n",
        "# TODO: Calculate the average training loss #\n",
        "avg_train_loss =\n",
        "\n",
        "# TODO: Extract the estimated number of members and non-members #\n",
        "num_member      =\n",
        "num_non_member =\n",
        "\n",
        "baseline_accuracy = (num_member + num_non_member) / (len(train_target_loader.dataset) + len(test_target_loader.dataset))\n",
        "\n",
        "print(\"Accuracy\", baseline_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d67d6b",
      "metadata": {
        "id": "c6d67d6b"
      },
      "source": [
        "## Part II: Membership Attack Loss Threshold (MALT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0e66a1",
      "metadata": {
        "id": "1f0e66a1"
      },
      "outputs": [],
      "source": [
        "def computeMetrics(train_losses: torch.tensor, test_losses: torch.tensor) -> float:\n",
        "    \"\"\"\n",
        "    We want to use this method to extract the loss value that achieves the best separation between\n",
        "    the losses of members <train_losses> and non-members <test_losses>.\n",
        "\n",
        "    The parameters are the negative losses such that the highest loss is now the lowest one (* -1).\n",
        "\n",
        "    The general idea is to sort the negative losses and then consider every loss as a possible threshold.\n",
        "\n",
        "    Hint: Keep in mind that, in general, loss values of members are much smaller than loss values of non-members.\n",
        "          However, since we operate on negative losses, the opposite is true.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Create a tensor that contains the indices of the sorted, concatenated training and test losses. #\n",
        "    order =\n",
        "\n",
        "    # TODO: This tensor holds the ground truth: starting with a '1' for every member followed by a '0' for every non-member #\n",
        "    membership =\n",
        "\n",
        "    # Number of correctly classified samples per threshold\n",
        "    accuracies = torch.zeros_like(membership)\n",
        "\n",
        "    # Hint: Keep in mind that the idea of a threshold is to separate non-members (on the left) from members (on the right).\n",
        "    #       Maybe it helps to imagine this threshold as a slider that gets pushed to the right from small loss values\n",
        "    #       to higher values.\n",
        "\n",
        "    for threshold in range(len(accuracies)):\n",
        "\n",
        "        # TODO: For every threshold:\n",
        "        #       Sum up the correctly classified non-members on the left side of the threshold and the correctly classified\n",
        "        #       members on the right side #\n",
        "        accuracies[threshold] =\n",
        "\n",
        "    # TODO: Use the accuracies to extract the index of the loss value with the best separation #\n",
        "    loss_index =\n",
        "\n",
        "    # TODO: Depending on whether the loss_index belongs to training or test samples output the corresponding loss value #\n",
        "    threshold_loss =\n",
        "\n",
        "    return -threshold_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8ef973",
      "metadata": {
        "id": "ce8ef973"
      },
      "outputs": [],
      "source": [
        "shadow_model = torch.load(\"./data/shadow_model.mdl\")\n",
        "\n",
        "# TODO: Get loss values of both shadow train and test data #\n",
        "train_losses =\n",
        "test_losses  =\n",
        "\n",
        "# Compute loss value which we want to use as threshold #\n",
        "threshold_loss = computeMetrics(-train_losses, -test_losses)\n",
        "\n",
        "# Extract estimated number of members and non_members\n",
        "num_member      = compare_with_loss(train_target_loader, threshold_loss, is_member=True)\n",
        "num_non_member  = compare_with_loss(test_target_loader, threshold_loss, is_member=False)\n",
        "\n",
        "malt_accuracy = (num_member + num_non_member) / (len(train_target_loader.dataset) + len(test_target_loader.dataset))\n",
        "\n",
        "print(\"Accuracy\", malt_accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}