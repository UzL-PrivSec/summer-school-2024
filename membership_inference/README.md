\begin{task}{CTF Exercise 2 (10 Points)}

In this CTF-exercise we want you to implement multiple membership inference attacks (MIA) but this time on the basis of the loss and not logits like in the first MIA-exercise. Therefore, this exercise sheet is combined with the next one which means that the deadline is in \textbf{two} weeks. Next week, we will publish another exercise which extends this exercise by an attack defense part. \\
This week's notebook contains a template for two loss-based MIAs separated into two distinct parts with gaps and todos. Both operate on the same target model trained on the \textit{CIFAR10}\footnote{\url{https://www.cs.toronto.edu/~kriz/cifar.html}}. \\

\textbf{Part I: Baseline(4 Points)} \\
Intuition: The average training loss of a model represents a good estimate for loss values corresponding to members. If a model suffers from overfitting then loss values of training samples (members) become quite small and loss values of test samples (non-members) become quite large. Since average accuracies and losses are often reported to make a comparison to other state-of-the-art models when a model gets published, this scenarios seems reasonable. \\ \\
Attack plan: Calculate the average training loss and compare it with every loss value from training and test data. We call samples a member if their loss value is smaller than the average training loss and the opposite holds for non-members. \\ \\
This attack is based on the baseline attack from Yeom et al.\footnote{\url{https://arxiv.org/pdf/1709.01604.pdf}}. Please fill in the missing gaps to complete the attack template. Then your attack should reach an accuracy around $67\%$. \\

\textbf{Part II: MALT (6 Points)} \\
Unfortunately, the last attack suffers from the following bias: A high loss value certainly belongs to a non-member. However, a small loss value can be a member or rather a non-member which resembles another member or is just easy to learn. Therefore, we choose to implement another attack which promises a better membership accuracy. \\ \\
Intuition: To get a better estimate for a loss value which achieves a good separation between members and non-members, we fall back to public data. Even though we do not know the private data (target\_data), we still know that it consists of certain images where similar ones (shadow\_data) are publicly available. We use public data to train a shadow model and then we use this shadow model to extract a loss value which serves as threshold to distinguish members from non-members. \\ \\
Attack plan: \\
We start by calculating all loss values for members and non-members which we already did in the previous attack. Then we determine the best loss value in the following way: We sort the negative losses so that previously high loss values (most likely non-members) are on the left and previously small loss values (most likely members) are on the right. On that basis, we iterate over the sorted, negative losses from the left to the right and use the ground truth to calculate an accuracy for every loss of how well it separates members from non-members. Once we extracted this specific loss value, we can use it instead of the average training loss in the attack of part I to calculate the membership for our target model. \\ \\
This attack is based on the membership attack loss threshold (MAST) from Sablayrolles et al.\footnote{\url{https://proceedings.mlr.press/v97/sablayrolles19a/sablayrolles19a.pdf}}. Please fill in the missing gaps to complete the attack template. Then your attack should reach an accuracy around $81\%$.